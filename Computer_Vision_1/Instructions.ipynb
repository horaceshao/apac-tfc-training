{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision 1 \n",
    "\n",
    "## Intro - Introduction to ML and Setup\n",
    "\n",
    "1. Watch all of the intro [videos](https://w.amazon.com/bin/view/MachineLearningUniversity/Video). \n",
    "2. [Set up SageMaker](../Setup.ipynb). \n",
    "3. Be sure to run additional setup steps for the course listed below.\n",
    "4. Add your name to the [roster sheet](https://quip-amazon.com/VKZiAgpGAutu/AAOD-Training). Contact the workshop leader for access issues.\n",
    "5. Make sure you have the office hours meeting invite.\n",
    "6. Make sure you are in added to the training chime room. \n",
    "7. Don't be shy. Come with questions to office hours sessions, or ask in chime room.\n",
    "\n",
    "> When working though notebooks, take the time to understand what every cell is doing. Read API docs, add your own code modifications, and go through related tutorials for new modules you have not worked with before. It is easy to just \"run\" though the notebook, but you will not learn anything by just clicking \"run\"!\n",
    "\n",
    "## Lesson 1 - ML Lifecycle, Image Processing, Intro to Neural Networks\n",
    "\n",
    "1. Read all the [day 1 lessons](https://mla.corp.amazon.com/computer-vision-i/cv-day-1-ml-lifecycle-image-processing-and-neural-networks/)\n",
    "2. If you need more help on frameworks, these [tutorials](https://mla.corp.amazon.com/computer-vision-i/day-1-computer-vision/libraries-and-frameworks/) will help. **Ignore all links to Eider notebooks** contained in the lessons. Use the corresponding notebooks in the [Lesson 1 folder](./Lesson_1). It is recommended you spend time this week running through **all the tutorials on this page**. These are all fundamental skills you need to have in order for this course and future courses to make sense.\n",
    "3. [Watch the day 1 lecture](https://drive.corp.amazon.com/documents/MLU%20Lectures/MLA/CV/March%2023-25,%202020/MLA-CV_DAY1_BRENT.mp4). Refer back to reading materials, ask question in chime, and stop and take tutorials for topics you don't understand.\n",
    "4. Work through the lab for this lesson [image classificatio lab](Lesson_1/Gluon_image_classification_example.ipynb)\n",
    "5. Attempt your first [submission](Submission_and_dataset_access.ipynb) using the test data set on a trained model. The leader board resets every Saturday, and is used globally.\n",
    "\n",
    "## Lesson 2 - Convolutional Neural Networks and Transfer Learning\n",
    "\n",
    "1. Read all the [day 2 lessons](https://mla.corp.amazon.com/computer-vision-i/cv-day-2-training-cnns-and-transfer-learning/). \n",
    "2. [Watch the day 2 lecture](https://drive.corp.amazon.com/documents/MLU%20Lectures/MLA/CV/March%2023-25,%202020/MLA-CV_DAY2_BRENT.mp4). \n",
    "3. Work through the lab for [Transfer learning example](Lesson_2/Transfer_learning_example.ipynb). There are additional [tutorial notebooks](Lesson_2).\n",
    "4. [Re-submit](Submission_and_dataset_access.ipynb) results based on your learnings from this lesson.\n",
    "\n",
    "## Lesson 3 - Convolutional Neural Networks and Transfer Learning\n",
    "1. Read all the [day 3 lessons](https://mla.corp.amazon.com/computer-vision-i/cv-day-3-advanced-cnns-object-detection-and-semantic-segmentation/). \n",
    "2. [Watch the day 3 lecture](https://drive.corp.amazon.com/documents/MLU%20Lectures/MLA/CV/March%2023-25,%202020/MLA-CV_DAY3_BRENT.mp4). \n",
    "3. Work through the lab for [Balancing_datasets_and_data_augmentation](Lesson_3/Balancing_datasets_and_data_augmentation.ipynb). There is also a [notebook with model zoo implementation of Resnet and Yolo](Lesson_3/detectors.ipynb). \n",
    "4. [Re-submit](Submission_and_dataset_access.ipynb) results based on your learnings from this lesson.\n",
    "\n",
    "\n",
    "## Additional Resources\n",
    "[Gluon CV Tutorial](https://gluon-cv.mxnet.io/tutorials/index.html)\n",
    "\n",
    "> Bonus points if you modify this notebook and send a pull request..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional setup steps for this course\n",
    "\n",
    "**Note** If you launched the notebook using the cloudformation template, you do not need to run the steps below. However, if you do run into errors regarding scikit-image or missing dataset, run the following cells below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Update scikit image\n",
    "We may need to update the scikit-image module due to an [issue](https://github.com/numpy/numpy/issues/12744) that was resolved in later versions. Uncomment the below if you run into errors. **Be sure to restart your kernal if you re-install.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U pip\n",
    "!pip install -U scikit-image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data\n",
    "All the data needed for the lab is available via cloud front."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "cloud_front_url = 'https://d8mrh1kj01ho9.cloudfront.net/workshop/cv1/data/'\n",
    "file_names = 'example_dataset.pkl,training_data.pkl,test_data.pkl,sample_model_output.csv'.split(',')\n",
    "\n",
    "for file_name in file_names:\n",
    "    print('downloading '+file_name)\n",
    "    urllib.request.urlretrieve (cloud_front_url + file_name, '/tmp/'+file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
